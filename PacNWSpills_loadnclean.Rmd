---
title: "PacNW spills data exploration"
output: html_notebook
---

### Some basic cleaning and manipulation of the [Pacific Northwest spills data](https://github.com/jamesrco/PacNWSpills/tree/master/data).

#### Load some necessary libraries

Currently, we'll need stringr, dplyr, measurements, in addition to base R. Some of these have quite a few dependencies.

```{r}

library(stringr)
library(dplyr)
library(lubridate)
library(measurements)

```

#### First, some data loading and cleaning.

##### DEQ spills data

Assumes working directory is location of script; data files in subordinate directory "data".

First, load in data.

```{r}

DEQSpillsData_raw <- read.csv("data/raw/DEQ/OregonSpillsData_ERIS_OC_03APR2018.csv", stringsAsFactors = FALSE)
DEQSpillsData <- DEQSpillsData_raw

```

Next, clean up data elements and convert to appropriate data types. Easy ones first; we'll deal with the Quantity field and some others later. We can see right off the bat that almost all fields need trailing whitespace removed.

```{r}

DEQSpillsData$OERS.Number_Yr <- as.numeric(str_match(DEQSpillsData$OERS.Number,"^[0-9]{4}"))
DEQSpillsData$OERS.Number_ID <- 
as.numeric(DEQSpillsData$OERS.Number %>% str_match("[0-9]{4}\\s$") %>% str_match("^[0-9]{4}"))

DEQSpillsData$ReleaseDate <- mdy(DEQSpillsData$Release.On.Date)

DEQSpillsData$Material <- as.factor(str_trim(DEQSpillsData$Material, side = "right"))

DEQSpillsData$Media <- as.factor(str_trim(DEQSpillsData$Media, side = "right"))

DEQSpillsData$Source <- as.factor(str_trim(DEQSpillsData$Source, side = "right"))

DEQSpillsData$RP.Org <- str_trim(DEQSpillsData$RP.Org, side = "right")

DEQSpillsData$RP.Address <- str_trim(DEQSpillsData$RP.Address, side = "right")

DEQSpillsData$RP.City <- str_trim(DEQSpillsData$RP.City, side = "right")

DEQSpillsData$RP.State <- as.factor(str_trim(DEQSpillsData$RP.State, side = "right"))

DEQSpillsData$RP.Zip <- as.numeric(str_trim(DEQSpillsData$RP.Zip, side = "right"))

DEQSpillsData$Site.Address <- str_trim(DEQSpillsData$Site.Address, side = "right")

DEQSpillsData$Site.City <- str_trim(DEQSpillsData$Site.City, side = "right")

DEQSpillsData$Site.State <- as.factor(str_trim(DEQSpillsData$Site.State, side = "right"))

DEQSpillsData$Site.Zip <- as.numeric(str_trim(DEQSpillsData$Site.Zip, side = "right"))

DEQSpillsData$Latitude <- as.numeric(str_trim(DEQSpillsData$Latitude, side = "right"))

DEQSpillsData$Longitude <- as.numeric(str_trim(DEQSpillsData$Longitude, side = "right"))

```

We can now eliminate some duplicate entries. Some appear to have been created for an earlier export to the PS/BC Oil Spill Task Force database.

How many duplicates do we have, to start?

```{r}

sum(duplicated(DEQSpillsData$OERS.Number))

```

Let's get rid of the easiest/most obvious cases first.

```{r}

# Eliminate true duplicates
DEQSpillsData <- DEQSpillsData %>% distinct(.keep_all = TRUE) # not that many of these

# Eliminate some duplicate entries that seem to have been created for earlier export for the PS/BC Oil Spill Database
DEQSpillsData <- DEQSpillsData[!((duplicated(DEQSpillsData$OERS.Number) | duplicated(DEQSpillsData$OERS.Number, fromLast = TRUE)) &
                                 DEQSpillsData$Media == "Coding for the PS/BC Oil Spill Database"),]

```

Let's see how many duplicates remain, at least according to OERS number:

```{r}

sum(duplicated(DEQSpillsData$OERS.Number))

```

Now we'll have to tackle some more difficult cases, in which some data will likely have to be merged. We also have some *apparent* duplicates that aren't really duplicates, e.g., separate entries for the same incident where more than one product was released. In addition, the media classifications used prior to ca. 2010 apparently led to the creation of quasi-duplicate entries for each spill that was fully contained to pavement or other secondary containment.

```{r}

sum(duplicated(DEQSpillsData$OERS.Number))

```

The quantity field is a little bit tougher. We'll need to retain qualitative information to describe special circumstances in some instances (e.g., use of "de minimus") and convert to standard units (liters) in all cases of volume. Also need to control for various differences in punctuation and notation for volumes of 0 or none. Can use the conv_unit function from package "measurements" to convert to standard units once we get our abbreviations in a form the function understands.

```{r}

DEQSpillsData$Qty_numeric <- as.numeric(str_trim(DEQSpillsData$Qty., side = "right"))
DEQSpillsData$Qty_qualitative <- rep("NA", dim(DEQSpillsData)[1])
DEQSpillsData$Qty_qualitative[which(is.na(DEQSpillsData$Qty_numeric))] <- str_trim(DEQSpillsData$Qty.[which(is.na(DEQSpillsData$Qty_numeric))], side = "right")

```

First, let's take a look at what kind of information we have in the qualitative "quantity" field.

```{r}

print(as.data.frame(table(DEQSpillsData$Qty_qualitative)))

```

How many total entries do we have to deal with?

```{r}

sum(as.data.frame(table(DEQSpillsData$Qty_qualitative))$Freq) -
  sum(DEQSpillsData$Qty_qualitative=="NA" & is.numeric(DEQSpillsData$Qty_numeric))

```

Okay, so we've got a bunch of stuff to deal with. Let's work through as many of these as we can without manually correcting or editing individual data elements. First, deal with blanks (assumed to mean no release) and harmonize numeric quantity with any instances of "None" or "none" in qualitative field:

```{r}

sum(DEQSpillsData$Qty_qualitative=="", na.rm = TRUE)

DEQSpillsData$Qty_numeric[DEQSpillsData$Qty_qualitative==""] <- 0

```

```{r}

length(grep("^[N|n]one",DEQSpillsData$Qty_qualitative))
length(grep("^(?i)No spill",DEQSpillsData$Qty_qualitative))

DEQSpillsData$Qty_numeric[grepl("^[N|n]one",DEQSpillsData$Qty_qualitative)] <- 0
DEQSpillsData$Qty_numeric[grepl("^(?i)No spill",DEQSpillsData$Qty_qualitative)] <- 0
DEQSpillsData$Qty_qualitative[grepl("^[N|n]one",DEQSpillsData$Qty_qualitative)] <- "None"
DEQSpillsData$Qty_qualitative[grepl("^(?i)No spill",DEQSpillsData$Qty_qualitative)] <- "None"


```

Also, standardize notation for cases where some variation of "Unknown" was reported:

```{r}

length(grep("^(?i)Unk",DEQSpillsData$Qty_qualitative))
length(grep("^(?i)Ukn",DEQSpillsData$Qty_qualitative))
sum(DEQSpillsData$Qty_qualitative=="?", na.rm = TRUE)

DEQSpillsData$Qty_qualitative[grepl("(?i)Unk",DEQSpillsData$Qty_qualitative)] <- "Unknown"
DEQSpillsData$Qty_qualitative[grepl("(?i)Ukn",DEQSpillsData$Qty_qualitative)] <- "Unknown"
DEQSpillsData$Qty_qualitative[DEQSpillsData$Qty_qualitative=="?"] <- "Unknown"

```

Instances of some variation of "trace" or "de minimis":

```{r}

sum(DEQSpillsData$Qty_qualitative %in% c("Trace", "trace", "tr", "De minimis", "de minimis", "deminimis", 
                                         "Deminimis", "Deminimus", "De minimus", "deminimus", "minimal", "Minimal"))

DEQSpillsData$Qty_qualitative[DEQSpillsData$Qty_qualitative %in% c("Trace", "trace", "tr", "De minimis",
                                         "de minimis", "deminimis", "Deminimis", "Deminimus", "De minimus",
                                         "deminimus", "minimal", "Minimal")] <- "De minimis"

```

Now, let's take a look again and see where we stand.

```{r}

print(as.data.frame(table(DEQSpillsData$Qty_qualitative)))

```

How many total entries haven't we dealt with?

```{r}

sum(as.data.frame(table(DEQSpillsData$Qty_qualitative))$Freq) -
  sum(DEQSpillsData$Qty_qualitative=="NA" & is.numeric(DEQSpillsData$Qty_numeric)) -
  sum(DEQSpillsData$Qty_qualitative=="" & DEQSpillsData$Qty_numeric==0) - 
  sum(grepl("^[N|n]one",DEQSpillsData$Qty_qualitative) & DEQSpillsData$Qty_numeric==0) -
  sum(DEQSpillsData$Qty_qualitative=="Unknown") -
  sum(DEQSpillsData$Qty_qualitative=="De minimis")
  
```

This is a much more manageable number. Let's address some additional issues categorically before we get to correcting individual data elements.

First, address records where a comma appears in the quantity.

```{r}

length(grep("^[0-9]{1,3}(,[0-9]{3})*$",DEQSpillsData$Qty_qualitative))
ind_Qtycommas <- grep("^[0-9]{1,3}(,[0-9]{3})*$",DEQSpillsData$Qty_qualitative) # obtain, store index to these records

DEQSpillsData$Qty_qualitative[ind_Qtycommas]
str_replace_all(DEQSpillsData$Qty_qualitative[ind_Qtycommas],",","")

DEQSpillsData$Qty_numeric[ind_Qtycommas] <-
  as.numeric(str_replace_all(DEQSpillsData$Qty_qualitative[ind_Qtycommas],",",""))
DEQSpillsData$Qty_qualitative[ind_Qtycommas] <- NA

```

Address quantities reported as ranges. In these cases, we'll split the difference of the two numbers (arithmetic mean) and then note in the qualitative field that these quantities are "Approxmiate"; we'll also address some other values which were entered as approximate using various notations.

```{r}

length(grep("^[0-9]*\\s*\\-\\s*[0-9]*$",DEQSpillsData$Qty_qualitative))
ind_Qtyranges <- grep("^[0-9]*\\s*\\-\\s*[0-9]*$",DEQSpillsData$Qty_qualitative)
DEQSpillsData$Qty_qualitative[ind_Qtyranges]

Qtyrange_lo <- str_extract(DEQSpillsData$Qty_qualitative[ind_Qtyranges],"^[0-9]*")
Qtyrange_hi <- str_extract(DEQSpillsData$Qty_qualitative[ind_Qtyranges],"[0-9]*$")
Qtyrange_mean <- (as.numeric(Qtyrange_lo)+as.numeric(Qtyrange_hi))/2

Qtyrange_mean

DEQSpillsData$Qty_numeric[ind_Qtyranges] <- Qtyrange_mean
DEQSpillsData$Qty_qualitative[ind_Qtyranges] <- c("Approximate")

```

Set the Qty_qualitative field to NA for entries which have quantities of 0.

```{r}

length(DEQSpillsData$Qty_numeric[DEQSpillsData$Qty_numeric==0 & DEQSpillsData$Qty_qualitative==""])

```

A quick inspection of the data reveals several additional issues: There are quite a few entries with the same OERS number that appear to be at least partial duplicates, and there are several entries with various quantities described in the free text "Description" field without corresponding quantity data in the "Qty." field. Both need to be addressed somehow.

DEQSpillsData$Qty_qualitative[DEQSpillsData$Qty_qualitative!="NA"]


